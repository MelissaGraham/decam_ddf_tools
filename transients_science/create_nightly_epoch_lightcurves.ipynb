{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c1cc48-6771-4408-ad06-a0e7d28b8fbd",
   "metadata": {},
   "source": [
    "# Create Nightly Epoch Lightcurves\n",
    "\n",
    "Contact: Melissa Graham\n",
    "\n",
    "Create nightly-epoch lightcurves for \"good\" candidates for all DECam DDF observations\n",
    "(not just those obtained in 2021, which was the focus of Paper I).\n",
    "Measure lightcurve summary parameters: time span, amplitude, minimum magnitude, and number of epochs.\n",
    "\n",
    "The first steps to identifying \"good\" candidates are:\n",
    " 1. Identify and reject \"bad\" objects (dections): objects with inappropriate photometry (too-small magnitude errors) or R/B scores < 0.1.\n",
    " 2. Reject all candidates (associations of objects) with < 10 objects (detections).\n",
    " 3. Reject all candidates with mean R/B scores < 0.4.\n",
    "\n",
    "This is slightly different from the 2021 process, which did not have inappropriate photometry \n",
    "and did not reject objects with R/B < 0.1.\n",
    "\n",
    "Then, for a given candidate, the photometry for all objects for a given filter on a given night \n",
    "(including those with R/B < 0.4) are combined to make nightly-epoch lightcurves.\n",
    "\n",
    "The \"Lonely Epoch\" flag is set to `True` for any single nightly-epoch photometry point\n",
    "for which the mean R/B score of its objects is < 0.4 **and** there is no epoch with a\n",
    "mean R/B score > 0.4 within 14 days.\n",
    "These \"lonely epochs\" are more likely to be spurious coincidences with artifacts and \n",
    "we don't want to include these epochs in our lightcurve summary paramters.\n",
    "\n",
    "Then the lightcurve summary parameters are calculated, excluding \"lonely epochs\".\n",
    "\n",
    "Finally, the lightcurves and lightcurve summary parameters for all \"good\" candidates\n",
    "are written out to two files:\n",
    " * all_nightly_epochs_files/candidate_lightcurves.dat\n",
    " * all_nightly_epochs_files/candidate_lightcurve_parameters.dat \n",
    "\n",
    "Columns are described in the file headers.\n",
    "\n",
    "These files are then used for all other work in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94c879-d742-4837-8d71-8d42e52ee505",
   "metadata": {},
   "source": [
    "## 0. Set up\n",
    "\n",
    "Import packages and connect to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4406d08-04a5-47d0-aefe-07b2d282fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import getpass\n",
    "import pandas\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from astropy.time import Time\n",
    "\n",
    "from copy import deepcopy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee172cb-f208-403e-b01d-2f788ca8ab04",
   "metadata": {},
   "source": [
    "Set up a few variables so we can plot lines by semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff641a-6c24-4ce5-8de3-9a3e8ee1cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "semesters = ['21A', '21B', '22A', '22B', '23A']\n",
    "sem_dates_isot = ['2021-02-01T00:00:00',\n",
    "                  '2021-08-01T00:00:00',\n",
    "                  '2022-02-01T00:00:00',\n",
    "                  '2022-08-01T00:00:00',\n",
    "                       '2023-02-01T00:00:00',\n",
    "             '2023-08-01T00:00:00']\n",
    "sem_dates = Time(sem_dates_isot, format='isot', scale='utc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f27ef-d5fa-4bdb-9a84-91df853207ba",
   "metadata": {},
   "source": [
    "Use the username decat_ro, in order to access `versiontags`, and connect to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c7461-8a81-49f7-aab9-a92ea944e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbuser = input(\"DB User: \")\n",
    "dbpasswd = getpass.getpass(\"DB Password: \")\n",
    "db = psycopg2.connect(f\"dbname='decat' user='{dbuser}' password='{dbpasswd}' host='decatdb.lbl.gov'\")\n",
    "db.autocommit = True\n",
    "cursor = db.cursor( cursor_factory = psycopg2.extras.DictCursor )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8c2f1-87c8-4d1e-80cb-faa825a525aa",
   "metadata": {},
   "source": [
    "If you want to print table schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e8a58-4585-4704-af10-9639033d203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables = ['versiontags','exposures','subtractions','images',\\\n",
    "#           'objects','objectrbs','objectdatas','objectdata_versiontag','candidates']\n",
    "# for table in tables:\n",
    "#     query = \"SELECT column_name, data_type FROM information_schema.columns WHERE table_name=%s\"\n",
    "#     cursor.execute( query, ( table, ))\n",
    "#     print( f\"\\nTABLE: {table}\\n===========================\" )\n",
    "#     for row in cursor:\n",
    "#         print( f\"{row['column_name']:24s}  :  {row['data_type']:s}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc11af-d1aa-48b3-913e-ce8ff0f8aede",
   "metadata": {},
   "source": [
    "Use the `latest` version of the `versiontags`, and print the `tagid`.\n",
    "\n",
    "The results in the database are tagged with versions so that data can be re-processed without\n",
    "being overwritten, and so that different algorithms can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694239b-31f3-488c-9c6f-c4a9c7bc66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"latest\"\n",
    "db.rollback()\n",
    "q = ( \"SELECT id, tag FROM versiontags WHERE tag=%(tag)s\" )\n",
    "cursor.execute( q, { \"tag\": tag } )\n",
    "row = cursor.fetchone()\n",
    "tagid = row['id']\n",
    "print(tagid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4699a12-a8d7-42a3-9c0f-8e47639e3dc5",
   "metadata": {},
   "source": [
    "## 1. Get all extragalactic objects\n",
    "\n",
    "### 1.1. Query the database\n",
    "\n",
    "Get all the objects in ELAIS and COSMOS fields, and print how many were retrieved.\n",
    "\n",
    "This takes about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58e2d9-adca-40bd-8a9b-689807d4849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "q = (\"SELECT od.ra, od.dec, od.mag, od.magerr, rbs.rb, \"\n",
    "     \"i.filter, i.meanmjd, o.candidate_id, e.proposalid \"\n",
    "     \"FROM objectdatas AS od \"\n",
    "     \"INNER JOIN objectdata_versiontag AS odvt \"\n",
    "     \"ON od.id=odvt.objectdata_id AND odvt.versiontag_id=%(tagid)s \"\n",
    "     \"INNER JOIN objects AS o ON od.object_id=o.id \"\n",
    "     \"INNER JOIN images AS i ON o.image_id=i.id \"\n",
    "     \"INNER JOIN objectrbs as rbs ON od.id=rbs.objectdata_id AND rbs.rbtype_id=2 \"\n",
    "     \"INNER JOIN exposures AS e ON i.exposure_id=e.id \"\n",
    "     \"WHERE ((od.ra > 147.0 AND od.ra < 153.0 AND od.dec > -0.25 AND od.dec < 5) \"\n",
    "     \"OR (od.ra > 5.0 AND od.ra < 12.0 AND od.dec > -46 AND od.dec < -41)) \")\n",
    "cursor.execute(q, {'tagid': tagid})\n",
    "df = pandas.DataFrame(cursor.fetchall())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c0283-0ba7-4d8d-8c22-257db6c720ac",
   "metadata": {},
   "source": [
    "Put the objects into numpy arrays.\n",
    "Prefix them with `raw_` because we will be reducing the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e6b80-fdc6-4fe7-9add-c92ce6bafbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_obj_ra     = np.asarray(df[0], dtype='float')\n",
    "raw_obj_dec    = np.asarray(df[1], dtype='float')\n",
    "raw_obj_mag    = np.asarray(df[2], dtype='float')\n",
    "raw_obj_mage   = np.asarray(df[3], dtype='float')\n",
    "raw_obj_rb     = np.asarray(df[4], dtype='float')\n",
    "raw_obj_filt   = np.asarray(df[5], dtype='str')\n",
    "raw_obj_mjd    = np.asarray(df[6], dtype='float')\n",
    "raw_obj_candid = np.asarray(df[7], dtype='str')\n",
    "raw_obj_propid = np.asarray(df[8], dtype='str')\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a8d45-a855-4c51-8e6c-fa346b7ee2af",
   "metadata": {},
   "source": [
    "### 1.2. Visualize object properties\n",
    "\n",
    "Plot a histogram of object detection dates.\n",
    "Overplot vertical lines for the semesters (magenta) and for today (red).\n",
    "\n",
    "Save the plot as `all_nightly_epochs_files/hist_obj_mjd.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7611c-f984-4576-b526-1b5d85bf9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(raw_obj_mjd, bins=100)\n",
    "for x in [0, 1, 2, 3, 4, 5]:\n",
    "    plt.axvline(sem_dates[x].mjd, color='magenta')\n",
    "for x in [0, 1, 2, 3, 4]:    \n",
    "    plt.text(sem_dates[x].mjd, 270000, semesters[x])\n",
    "plt.axvline(Time.now().mjd, color='red')\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel('# Objects')\n",
    "plt.title('COSMOS & ELAIS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd57e3-bebf-46b9-bbab-daae24dc6418",
   "metadata": {},
   "source": [
    "Plot relations between the object magnitude, R/B score, and magnitude errors (for all filters, all together).\n",
    "\n",
    "Notice the second population of objects with too-small magnitude errors in semesters 22B and 23A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410392a-9a62-44e5-9378-b0524f0b3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 3, figsize=(12, 15))\n",
    "for x in [0, 1, 2, 3, 4]:\n",
    "    tx = np.where((raw_obj_mjd > sem_dates[x].mjd) & \n",
    "                  (raw_obj_mjd <= sem_dates[x+1].mjd) & \n",
    "                  np.isfinite(raw_obj_mag) & \n",
    "                  np.isfinite(raw_obj_rb) & \n",
    "                  np.isfinite(raw_obj_mage))[0]\n",
    "    \n",
    "    # heatmap version\n",
    "    ax[x, 0].hist2d(raw_obj_mag[tx], raw_obj_rb[tx], bins=50, range=[[15, 25],[0.0,1.0]], \n",
    "                    cmap='Greys', norm=LogNorm(clip=True))\n",
    "    ax[x, 1].hist2d(raw_obj_mag[tx], raw_obj_mage[tx], bins=50, range=[[15, 25],[0.0,0.3]], \n",
    "                    cmap='Greys', norm=LogNorm(clip=True))\n",
    "    ax[x, 2].hist2d(raw_obj_rb[tx], raw_obj_mage[tx], bins=50, range=[[0.0,1.0],[0.0,0.3]], \n",
    "                    cmap='Greys', norm=LogNorm(clip=True))\n",
    "    \n",
    "    # scatterplot version\n",
    "    # ax[x, 0].plot(raw_obj_mag[tx], raw_obj_rb[tx], 'o', ms=2, alpha=0.05, mew=0, color='grey')\n",
    "    # ax[x, 1].plot(raw_obj_mag[tx], raw_obj_mage[tx], 'o', ms=2, alpha=0.05, mew=0, color='grey')\n",
    "    # ax[x, 2].plot(raw_obj_rb[tx], raw_obj_mage[tx], 'o', ms=2, alpha=0.05, mew=0, color='grey')\n",
    "\n",
    "    # plot R/B=0.1 line and set title for left column\n",
    "    ax[x, 0].axhline(0.1, color='black')\n",
    "    ax[x, 0].set_title(semesters[x]+' (N='+str(len(tx))+')')    \n",
    "    \n",
    "    # set axes labels and limits\n",
    "    ax[x, 0].set_xlabel('Magnitude')\n",
    "    ax[x, 0].set_xlim([15, 25])\n",
    "    ax[x, 0].set_ylabel('R/B Score')\n",
    "    ax[x, 0].set_ylim([-0.05,1.05])\n",
    "    ax[x, 1].set_xlabel('Magnitude')\n",
    "    ax[x, 1].set_xlim([15, 25])\n",
    "    ax[x, 1].set_ylabel('Magnitude Error')\n",
    "    ax[x, 1].set_ylim([0.0,0.3])\n",
    "    ax[x, 2].set_xlabel('R/B Score')\n",
    "    ax[x, 2].set_xlim([-0.05,1.05])\n",
    "    ax[x, 2].set_ylabel('Magnitude Error')\n",
    "    ax[x, 2].set_ylim([0.0,0.3])\n",
    "    \n",
    "    del tx\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b787b314-dc76-48ad-a1f5-eab93cdddb2e",
   "metadata": {},
   "source": [
    "Explore these objects with very small magnitude errors.\n",
    "This is a problem and they should probably not be used.\n",
    "\n",
    "Figure out how to make a cut in magnitude error *vs.* magnitude to isolate and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebca880-6a9e-42ee-a787-4541c71c001d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(12, 9))\n",
    "for x in [0, 1, 2]:\n",
    "    sx = x + 2\n",
    "    tx = np.where((raw_obj_mjd > sem_dates[sx].mjd) & \n",
    "                  (raw_obj_mjd <= sem_dates[sx+1].mjd) & \n",
    "                  np.isfinite(raw_obj_mag) & \n",
    "                  np.isfinite(raw_obj_rb) & \n",
    "                  np.isfinite(raw_obj_mage))[0]\n",
    "    \n",
    "    # plot heatmaps\n",
    "    ax[x, 0].hist2d(raw_obj_mag[tx], raw_obj_mage[tx], bins=50, range=[[15, 25],[0.0,0.01]], \n",
    "                    cmap='Greys', norm=LogNorm(clip=True))\n",
    "    ax[x, 1].hist2d(raw_obj_mag[tx], raw_obj_mage[tx], bins=50, range=[[15, 25],[0.0,0.3]], \n",
    "                    cmap='Greys', norm=LogNorm(clip=True))\n",
    "    ax[x, 2].hist2d(raw_obj_rb[tx], raw_obj_mage[tx], bins=50, range=[[0.0,1.0],[0.0,0.3]], \n",
    "                    cmap='Greys', norm=LogNorm(clip=True))\n",
    "    \n",
    "    # define by hand\n",
    "    xvals = np.asarray([15,   16,     17,   18,     19,    20,    21,   22,    23,   24,   25], dtype='float')\n",
    "    yvals = np.asarray([5E-4, 7.5E-4, 1E-3, 1.5E-3, 3E-3, 5E-3, 0.01, 0.024, 0.06, 0.12, 0.25], dtype='float')\n",
    "    ax[x, 0].plot(xvals, yvals, 'o', ms=2, color='red')\n",
    "    ax[x, 1].plot(xvals, yvals, 'o', ms=2, color='red')\n",
    "    # interpolate the hand-defined function\n",
    "    cutoff_xvals = 15.0 + 0.1 * np.arange(((25 - 15) * 10) + 1, dtype='float')\n",
    "    cutoff_yvals = np.interp(cutoff_xvals, xvals, yvals)\n",
    "    ax[x, 0].plot(cutoff_xvals, cutoff_yvals, 'o', ms=1, color='darkgreen')\n",
    "    ax[x, 1].plot(cutoff_xvals, cutoff_yvals, 'o', ms=1, color='darkgreen')\n",
    "    del xvals, yvals\n",
    "            \n",
    "    # set title for left column\n",
    "    ax[x, 0].set_title(semesters[sx]+' (N='+str(len(tx))+')')    \n",
    "    \n",
    "    # set axes labels and limits\n",
    "    ax[x, 0].set_xlabel('Magnitude')\n",
    "    ax[x, 0].set_xlim([14.5, 22])\n",
    "    ax[x, 0].set_ylabel('Magnitude Error')\n",
    "    ax[x, 0].set_ylim([0.0,0.01])\n",
    "    ax[x, 1].set_xlabel('Magnitude')\n",
    "    ax[x, 1].set_xlim([20, 25.5])\n",
    "    ax[x, 1].set_ylabel('Magnitude Error')\n",
    "    ax[x, 1].set_ylim([0.0,0.3])\n",
    "    ax[x, 2].set_xlabel('R/B Score')\n",
    "    ax[x, 2].set_xlim([-0.05,1.05])\n",
    "    ax[x, 2].set_ylabel('Magnitude Error')\n",
    "    ax[x, 2].set_ylim([0.0,0.3])\n",
    "    \n",
    "    del sx, tx\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669e922-6ad8-4baf-943a-8a0860622816",
   "metadata": {},
   "source": [
    "### 1.3. Flag objects with too-small magnitude errors\n",
    "\n",
    "Flag all objects that have magnitude errors below the interpolated green-dotted line.\n",
    "\n",
    "The value of `raw_obj_mage_flag` = True (= 1) when the value of `raw_obj_mage` is less than\n",
    "the cutoff limit (green dots above) for that object's value of `raw_obj_mag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e74788-1aca-46bc-ac1a-50fb8755a90c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_obj_mage_cutoff = np.interp(raw_obj_mag, cutoff_xvals, cutoff_yvals)\n",
    "raw_obj_mage_flag = np.zeros(len(raw_obj_mage), dtype='int')\n",
    "tx = np.where(raw_obj_mage_cutoff > raw_obj_mage)[0]\n",
    "raw_obj_mage_flag[tx] = 1\n",
    "print('Number of flagged objects: ', len(tx))\n",
    "print('Fraction of objects flagged: ', np.round(len(tx)/len(raw_obj_mag),2))\n",
    "del tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34f752-0c7d-45b3-a473-e4aefef35bcd",
   "metadata": {},
   "source": [
    "## 2. Identify \"good\" candidates, 2021-2022\n",
    "\n",
    "### 2.1. Delete \"bad\" objects\n",
    "\n",
    "Delete all objects with an R/B < 0.1 or with a magnitude error flag of `True` or\n",
    "with an MJD past the start of 2023A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec8121-c5f7-4a09-9fc2-8e7b55daeaca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dx = np.where((raw_obj_rb < 0.1) | \n",
    "              (raw_obj_mage_cutoff == 1) | \n",
    "              (raw_obj_mjd > sem_dates[4].mjd))[0]\n",
    "\n",
    "tmp_obj_ra     = np.delete(raw_obj_ra, dx)\n",
    "tmp_obj_dec    = np.delete(raw_obj_dec, dx)\n",
    "tmp_obj_mag    = np.delete(raw_obj_mag, dx)\n",
    "tmp_obj_mage   = np.delete(raw_obj_mage, dx)\n",
    "tmp_obj_rb     = np.delete(raw_obj_rb, dx)\n",
    "tmp_obj_filt   = np.delete(raw_obj_filt, dx)\n",
    "tmp_obj_mjd    = np.delete(raw_obj_mjd, dx)\n",
    "tmp_obj_candid = np.delete(raw_obj_candid, dx)\n",
    "tmp_obj_propid = np.delete(raw_obj_propid, dx)\n",
    "\n",
    "print('Number of objects deleted: ', len(dx))\n",
    "print('As a fraction of total raw objects: ', np.round(len(dx)/len(raw_obj_ra), 2))\n",
    "print('Number of objects remaining: ', len(tmp_obj_ra))\n",
    "\n",
    "del dx\n",
    "del raw_obj_ra, raw_obj_dec, raw_obj_mag, raw_obj_mage\n",
    "del raw_obj_rb, raw_obj_filt, raw_obj_mjd, raw_obj_candid, raw_obj_propid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12946c6a-c3c8-4f39-9a2b-98ae70389514",
   "metadata": {},
   "source": [
    "### 2.2. Identify \"good\" candidates\n",
    "\n",
    "#### 2.2.1. Delete candidates with < 10 objects\n",
    "\n",
    "Get the unique candidate ids, and delete all candidates (and their objects)\n",
    "for which the number of objects per candidate is < 10.\n",
    "\n",
    "Documentation for `numpy.unique`: https://numpy.org/doc/stable/reference/generated/numpy.unique\n",
    "\n",
    "```\n",
    "values  : sorted unique candidate ids\n",
    "indices : the indices of `tmp_obj_candid` that give `values`\n",
    "inverse : the indices of `values` that reconstruct `tmp_obj_candid`\n",
    "counts  : the number of times each unique candidate id appears in `tmp_obj_candid`\n",
    "```\n",
    "\n",
    "In other words, `counts` is the number of objects per candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0eb357-0c27-4b6a-bee1-49eb8aef9577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values, indices, inverse, counts = np.unique(tmp_obj_candid, return_index=True, \n",
    "                                             return_inverse=True,  return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe98959-d5d2-4bbf-98c5-0e4d857c3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('On average, %4.2f objects per candidate' % (len(tmp_obj_candid)/len(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe677a4-8255-4671-83c4-216913ee265a",
   "metadata": {},
   "source": [
    "Plot the distribution of the number of objects per candidate.\n",
    "Draw a horizontal line at 10, the cutoff we will apply for \"good\" candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b7477-776f-4835-9583-d79f7dce3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(counts), bins=100, log=True, alpha=0.5, color='grey')\n",
    "plt.axvline(np.log10(10), ls='solid', lw=1, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6e0bf-981b-4521-b005-3266a6a0166e",
   "metadata": {},
   "source": [
    "Delete all objects of candidates with less than 10 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ef555-7249-4196-9f3c-0aeef573a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.where(counts[inverse] < 10)[0]\n",
    "\n",
    "obj_ra     = np.delete(tmp_obj_ra, dx)\n",
    "obj_dec    = np.delete(tmp_obj_dec, dx)\n",
    "obj_mag    = np.delete(tmp_obj_mag, dx)\n",
    "obj_mage   = np.delete(tmp_obj_mage, dx)\n",
    "obj_rb     = np.delete(tmp_obj_rb, dx)\n",
    "obj_filt   = np.delete(tmp_obj_filt, dx)\n",
    "obj_mjd    = np.delete(tmp_obj_mjd, dx)\n",
    "obj_candid = np.delete(tmp_obj_candid, dx)\n",
    "obj_propid = np.delete(tmp_obj_propid, dx)\n",
    "\n",
    "print('Number of objects deleted: ', len(dx))\n",
    "print('As a fraction of current number of objects: ', np.round(len(dx)/len(tmp_obj_ra), 2))\n",
    "print('Number of objects remaining: ', len(obj_ra))\n",
    "\n",
    "del dx\n",
    "del tmp_obj_ra, tmp_obj_dec, tmp_obj_mag, tmp_obj_mage\n",
    "del tmp_obj_rb, tmp_obj_filt, tmp_obj_mjd, tmp_obj_candid, tmp_obj_propid\n",
    "del values, indices, inverse, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c6e5d-dc93-4fe2-934d-ee9ea4f40da3",
   "metadata": {},
   "source": [
    "Get the number of unique candidates now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a3335-163f-4195-bfa8-9468e530c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices, inverse, counts = np.unique(obj_candid, return_index=True, \n",
    "                                             return_inverse=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a3fbe-1dc3-4b82-88dd-b8108295e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('On average, %4.2f objects per candidate' % (len(obj_candid)/len(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cad1b8-2ba0-40ea-85b0-553056fc46fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.2. Delete candidates with mean R/B < 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a93e0-4fa9-4bf9-9719-1ba26e12e18d",
   "metadata": {},
   "source": [
    "Create temporary arrays to hold candidate info:\n",
    "\n",
    "```\n",
    "cand_ids    : list of unqiue candidates\n",
    "cand_nobjs  : number of objects per candidate\n",
    "cand_meanrb : mean R/B score for candidates' objects\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a50988-a8c4-4769-8843-e4d61fcf6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cand_ids = values\n",
    "tmp_cand_nobjs = counts\n",
    "tmp_cand_meanrb = np.zeros(len(tmp_cand_ids), dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a3263-238b-4b2e-ad96-13b1cf80a794",
   "metadata": {},
   "source": [
    "Calculate the mean R/B score for each candidate, `cand_mrb`.\n",
    "\n",
    "This takes about 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaadc86-5de1-4754-affa-5ade8c27ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t0 = time.time()\n",
    "for c, cid in enumerate(tmp_cand_ids):\n",
    "    if (c == 100) | (c == 1000) | (c == 10000):\n",
    "        t1 = time.time()\n",
    "        print('c = %5i, elapsed = %5.1f seconds' % (c, t1 - t0))\n",
    "        del t1\n",
    "    cx = np.where(obj_candid == cid)[0]\n",
    "    tmp_cand_nobjs[c] = len(cx)\n",
    "    tmp_cand_meanrb[c] = np.nanmean(obj_rb[cx])\n",
    "    del cx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b24238-31d4-47d5-8a55-88480b348dd2",
   "metadata": {},
   "source": [
    "Delete candidates with a mean R/B score < 0.4 from the candidate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbddcf-6661-4d87-a61f-7587cd2eacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.where(tmp_cand_meanrb < 0.4)[0]\n",
    "\n",
    "cand_ids = np.delete(tmp_cand_ids, dx)\n",
    "cand_nobjs = np.delete(tmp_cand_nobjs, dx)\n",
    "cand_meanrb = np.delete(tmp_cand_meanrb, dx)\n",
    "\n",
    "print('Number of candidates deleted: ', len(dx))\n",
    "print('As a fraction of current number of candidates: ', np.round(len(dx)/len(tmp_cand_ids), 2))\n",
    "print('Number of candidates remaining: ', len(cand_ids))\n",
    "\n",
    "del dx\n",
    "del tmp_cand_ids, tmp_cand_nobjs, tmp_cand_meanrb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f579eb7-0d83-45a5-bae4-a5319da7eedd",
   "metadata": {},
   "source": [
    "## 3. Create candidate nightly-epoch lightcurves\n",
    "\n",
    "\"Nightly-epoch\" means all observations per filter per candidate in a given \n",
    "night are combined into a single photometry point.\n",
    "\n",
    "Although we have limited only to candidates with mean R/B scores over\n",
    "*all* objects are > 0.4, an individual nightly-epoch might have a mean R/B < 0.4.\n",
    "\n",
    "### 3.1. Combine photometry into nightly-epochs\n",
    "\n",
    "Use lists, first, and prefix with `tmp`.\n",
    "Then store results in numpy arrays.\n",
    "\n",
    "```\n",
    "ne_candid : candidate id\n",
    "ne_field  : field (COSMOS or ELAIS)\n",
    "ne_cal    : calendar date\n",
    "ne_mjd    : modified julian date\n",
    "ne_fil    : filter (g, r, i)\n",
    "ne_nobj   : number of objects combined\n",
    "ne_mag    : combined magnitude\n",
    "ne_mage   : combined magnitude error\n",
    "ne_mrb    : mean R/B score of combined objects\n",
    "```\n",
    "\n",
    "This takes about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45bedf-c26c-4329-96b4-97417a9b0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "tmp_ne_candid = []\n",
    "tmp_ne_field = []\n",
    "tmp_ne_cal = []\n",
    "tmp_ne_mjd = []\n",
    "tmp_ne_fil = []\n",
    "tmp_ne_nobj = []\n",
    "tmp_ne_mag = []\n",
    "tmp_ne_mage = []\n",
    "tmp_ne_mrb = []\n",
    "\n",
    "for c in range(len(cand_ids)):\n",
    "    tally_ne = 0\n",
    "    \n",
    "    if (c == 10) | (c == 100) | (c == 1000):\n",
    "        t2 = time.time()\n",
    "        print('c=%6i, %5.1f seconds remain' % (c, ((t2-t1)/float(c))*(float(len(cand_ids)-c))))\n",
    "       \n",
    "    cx = np.where(obj_candid == cand_ids[c])[0]\n",
    "    \n",
    "    if (np.mean(obj_ra[cx]) > 5.0) & (np.mean(obj_ra[cx]) < 12.0):\n",
    "        field = 'ELAIS'\n",
    "    else:\n",
    "        field = 'COSMOS'\n",
    "    \n",
    "    mjds = obj_mjd[cx]\n",
    "    temp = Time(mjds, format='mjd')\n",
    "    temp2 = temp.isot\n",
    "    temp3 = []\n",
    "    for i in temp2:\n",
    "        temp3.append(i[0:10])    \n",
    "    ucals, indices = np.unique(temp3, return_index=True)\n",
    "    umjds = mjds[indices]\n",
    "    del temp, temp2, temp3, indices\n",
    "\n",
    "    for d, mjd in enumerate(umjds):\n",
    "        \n",
    "        for f, fil in enumerate(['g','r','i']):\n",
    "            fx = np.where((np.abs(obj_mjd[cx] - mjd) < 0.4) & \n",
    "                          (obj_filt[cx] == fil) & \n",
    "                          (np.isfinite(obj_mag[cx])) & \n",
    "                          (obj_mag[cx] > 0.0))[0]\n",
    "            \n",
    "            if len(fx) >= 2:\n",
    "                tmp_ne_field.append(field)\n",
    "                tmp_ne_candid.append(cand_ids[c])\n",
    "                tmp_ne_cal.append(ucals[d])\n",
    "                tmp_ne_mjd.append(np.mean(obj_mjd[cx[fx]]))\n",
    "                tmp_ne_fil.append(fil)\n",
    "                tmp_ne_nobj.append(len(obj_mjd[cx[fx]]))\n",
    "                tmp_ne_mag.append(np.mean(obj_mag[cx[fx]]))\n",
    "                tmp_ne_mage.append(np.sqrt(np.mean(obj_mage[cx[fx]])**2 + \\\n",
    "                                            np.std(obj_mag[cx[fx]])**2))\n",
    "                tmp_ne_mrb.append(np.mean(obj_rb[cx[fx]]))\n",
    "                tally_ne += 1\n",
    "            \n",
    "            elif len(fx) == 1:\n",
    "                tmp_ne_field.append(field)\n",
    "                tmp_ne_candid.append(cand_ids[c])\n",
    "                tmp_ne_cal.append(ucals[d])\n",
    "                tmp_ne_mjd.append(obj_mjd[cx[fx[0]]])\n",
    "                tmp_ne_fil.append(fil)\n",
    "                tmp_ne_nobj.append(1)\n",
    "                tmp_ne_mag.append(obj_mag[cx[fx[0]]])\n",
    "                tmp_ne_mage.append(obj_mage[cx[fx[0]]])\n",
    "                tmp_ne_mrb.append(obj_rb[cx[fx[0]]])\n",
    "                tally_ne += 1\n",
    "                \n",
    "            del fx\n",
    "    \n",
    "    if tally_ne == 0:\n",
    "        print('warning: ', cand_id[c], ' no nightly epochs with detections')\n",
    "    del cx\n",
    "\n",
    "ne_field  = np.asarray(tmp_ne_field, dtype='str')\n",
    "ne_candid = np.asarray(tmp_ne_candid, dtype='str')\n",
    "ne_nobj   = np.asarray(tmp_ne_nobj, dtype='int')\n",
    "ne_mjd    = np.asarray(tmp_ne_mjd, dtype='float')\n",
    "ne_cal    = np.asarray(tmp_ne_cal, dtype='str')\n",
    "ne_fil    = np.asarray(tmp_ne_fil, dtype='str')\n",
    "ne_mag    = np.asarray(tmp_ne_mag, dtype='float')\n",
    "ne_mage   = np.asarray(tmp_ne_mage, dtype='float')\n",
    "ne_mrb    = np.asarray(tmp_ne_mrb, dtype='float')\n",
    "\n",
    "del tmp_ne_field, tmp_ne_candid, tmp_ne_nobj, tmp_ne_mjd, tmp_ne_cal\n",
    "del tmp_ne_fil, tmp_ne_mag, tmp_ne_mage, tmp_ne_mrb, tally_ne\n",
    "\n",
    "t2 = time.time()\n",
    "print('elapsed: %5.1f' % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0b895-e4d5-4651-8a26-407179f1409d",
   "metadata": {},
   "source": [
    "### 3.1. Create the \"lonely epoch\" flag\n",
    "\n",
    "As described above, an individual nightly-epoch might have a mean R/B < 0.4.\n",
    "\n",
    "These low-R/B nightly-epochs do contribute to the lightcurve summary parameters,\n",
    "but only if they are not a \"*lonely epoch*\".\n",
    "\n",
    "A \"*lonely epoch*\" is a nightly-epoch, for a given filter, for which the \n",
    "mean R/B score of its objects is < 0.4 *and* there is no other epoch\n",
    "within 14 days for which the mean R/B score was > 0.4 (in any filter).\n",
    "\n",
    "\"*Lonely epochs*\" are much more likely to be spurious detections that\n",
    "are coincident with a candidate, and can throw off the values of the\n",
    "lightcurve summary parameters (e.g., extend the time span).\n",
    "\n",
    "```\n",
    "ne_loneflag : lonely epoch flag (True if it is a lonely epoch)\n",
    "```\n",
    "\n",
    "This takes a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aab337-538d-480e-895d-28e05bac4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "ne_loneflag = np.zeros(len(ne_mrb), dtype='int')\n",
    "\n",
    "for c, cand in enumerate(cand_ids):\n",
    "\n",
    "    if (c == 10) | (c == 100) | (c == 1000):\n",
    "        t2 = time.time()\n",
    "        print('c=%6i, %5.1f seconds remain' % (c, ((t2-t1)/float(c))*(float(len(cand_ids)-c))))\n",
    "    \n",
    "    for f, filt in enumerate(['g','r','i']):\n",
    "        tx1 = np.where((ne_candid == cand) & (ne_fil == filt))[0]\n",
    "        tx2 = np.where((ne_candid == cand) & (ne_fil == filt) & (ne_mrb > 0.4))[0]\n",
    "        \n",
    "        if len(tx1) == 1:\n",
    "            if ne_mrb[tx1[0]] < 0.4:\n",
    "                ne_loneflag[tx1[0]] = 1\n",
    "        elif (len(tx1) > 1) & (len(tx2) == 0):\n",
    "            for x1 in tx1:\n",
    "                ne_loneflag[x1] = 1            \n",
    "        elif (len(tx1) > 1) & (len(tx2) > 0):\n",
    "            for i, x1 in enumerate(tx1):\n",
    "                if ne_mrb[x1] < 0.4:\n",
    "                    nearest_good = np.min(np.abs(ne_mjd[x1] - ne_mjd[tx2]))\n",
    "                    if nearest_good > 14:\n",
    "                        ne_loneflag[x1] = 1\n",
    "                    del nearest_good\n",
    "        \n",
    "        del tx1, tx2\n",
    "\n",
    "t2 = time.time()\n",
    "print('elapsed: %5.1f' % (t2 - t1))\n",
    "del t1, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addbc235-0b96-4d59-bd79-8f162ca72a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.where(ne_loneflag == 1)[0]\n",
    "print('Number and fraction of lonely epochs: ', len(tx), np.round(len(tx)/len(ne_loneflag), 2))\n",
    "del tx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec289d-7ea3-4184-afe9-1881b49dfb6a",
   "metadata": {},
   "source": [
    "### 3.2. Write the nightly-epoch lightcurves to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530db449-bcff-4d25-aad2-169b01767a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnm = 'all_nightly_epochs_files/candidate_lightcurves.dat'\n",
    "fout = open(fnm, 'w')\n",
    "\n",
    "fout.write('# Melissa Graham, candidate_nightly_epochs.ipynb \\n')\n",
    "tnow = time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime())\n",
    "fout.write('# UTC = '+tnow+' \\n')\n",
    "del tnow\n",
    "fout.write('# \\n')\n",
    "fout.write('# Columns \\n')\n",
    "fout.write('#  0 field  \\n')\n",
    "fout.write('#  1 id -- candidate identifier \\n')\n",
    "fout.write('#  2 calendar date \\n')\n",
    "fout.write('#  3 MJD \\n')\n",
    "fout.write('#  4 filter \\n')\n",
    "fout.write('#  5 number of objects combined \\n')\n",
    "fout.write('#  6 magnitude (mean of objects combined) \\n')\n",
    "fout.write('#  7 magnitude error \\n')\n",
    "fout.write('#  8 real/bogus (mean of objects combined) \\n')\n",
    "fout.write('#  9 lonely epoch flag \\n')\n",
    "fout.write('# \\n')\n",
    "\n",
    "for i in range(len(ne_candid)):\n",
    "    fout.write('%-9s %-14s %-8s %12.6f '\\\n",
    "               '%1s %3i %6.3f %6.3f %6.4f %1i \\n' % \\\n",
    "               (ne_field[i], ne_candid[i], ne_cal[i], ne_mjd[i], \\\n",
    "                ne_fil[i], ne_nobj[i], ne_mag[i], ne_mage[i], ne_mrb[i], ne_loneflag[i]) )\n",
    "\n",
    "fout.close()\n",
    "print('Wrote to: ', fnm)\n",
    "del fnm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c6e28-92b9-4fb0-adc3-690e10f07e9f",
   "metadata": {},
   "source": [
    "## 4. Calculate the lightcurve summary parameters\n",
    "\n",
    "Recall that \"lonely epochs\" are not included in the calculation of the summary parameters.\n",
    "\n",
    "Lightcurve summary parameters include:\n",
    "\n",
    "```\n",
    "tspan  : time span, the mjd of the last minus the first nightly-epoch\n",
    "minmag : minimum magnitude, apparent magnitude of the brightest nightly-epoch\n",
    "lcamp  : lightcurve amplitude, the difference between the brightest and faintest nightly-epoch\n",
    "nde    : number of non-lonely epochs\n",
    "```\n",
    "\n",
    "This takes a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee17ed-d6c9-4c93-b249-164fd4971d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "### timespan (last date - first date of detection)\n",
    "nelc_tspan = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_tspan_g = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_tspan_r = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_tspan_i = np.zeros( len(cand_ids), dtype='float' )\n",
    "\n",
    "### minimum magnitude (brightest detection)\n",
    "nelc_minmag = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_minmag_g = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_minmag_r = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_minmag_i = np.zeros( len(cand_ids), dtype='float' )\n",
    "\n",
    "### amplitude (maximum - minimum detection)\n",
    "nelc_lcamp = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_lcamp_g = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_lcamp_r = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_lcamp_i = np.zeros( len(cand_ids), dtype='float' )\n",
    "\n",
    "### number of epochs with detections\n",
    "nelc_nde = np.zeros( len(cand_ids), dtype='int' )\n",
    "nelc_nde_g = np.zeros( len(cand_ids), dtype='int' )\n",
    "nelc_nde_r = np.zeros( len(cand_ids), dtype='int' )\n",
    "nelc_nde_i = np.zeros( len(cand_ids), dtype='int' )\n",
    "\n",
    "tempfield = []\n",
    "\n",
    "### for every candidate\n",
    "for c, candid in enumerate(cand_ids):\n",
    "    if (c == 10) | (c == 100) | (c == 1000):\n",
    "        t2 = time.time()\n",
    "        print('c=%6i, %5.1f seconds remain' % (c, ((t2-t1)/float(c))*(float(len(cand_ids)-c))))\n",
    "        \n",
    "    ### at first, skip the loneflag constraint to fill tempfield and check mag issues\n",
    "    cx = np.where( (ne_candid == candid) & (ne_nobj >= 1) )[0]\n",
    "    tempfield.append(ne_field[cx[0]])\n",
    "    ### where the nobj >= 1, the mag should never be nan\n",
    "    tx = np.where( np.isnan( ne_mag[cx] ) )[0]\n",
    "    if len(tx) != 0:\n",
    "        print('warning, ', candid, ' has a nobj >=1, mag=nan epoch')\n",
    "    del tx\n",
    "\n",
    "    ### but now, can apply the loneflag constraint if wanted\n",
    "    # cx = np.where( (ne_candid == candid) & (ne_nobj >= 1) )[0]\n",
    "    cx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_loneflag == 0) )[0]\n",
    "    if len(cx) > 0:\n",
    "        temp = np.unique( ne_cal[cx] )\n",
    "        nelc_nde[c] = len(temp)\n",
    "        del temp\n",
    "        nelc_tspan[c]  = np.max( ne_mjd[cx] ) - np.min( ne_mjd[cx] )\n",
    "        nelc_minmag[c] = np.min( ne_mag[cx] )\n",
    "        nelc_lcamp[c]  = np.max( ne_mag[cx] ) - np.min( ne_mag[cx] )\n",
    "    del cx\n",
    "\n",
    "    # gx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'g') )[0]\n",
    "    # rx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'r') )[0]\n",
    "    # ix = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'i') )[0]\n",
    "    gx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'g') & (ne_loneflag == 0) )[0]\n",
    "    rx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'r') & (ne_loneflag == 0) )[0]\n",
    "    ix = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'i') & (ne_loneflag == 0) )[0]\n",
    "    if len(gx) > 0:\n",
    "        nelc_nde_g[c]    = len(gx)\n",
    "        nelc_tspan_g[c]  = np.max( ne_mjd[gx] ) - np.min( ne_mjd[gx] )\n",
    "        nelc_minmag_g[c] = np.min( ne_mag[gx] )\n",
    "        nelc_lcamp_g[c]  = np.max( ne_mag[gx] ) - np.min( ne_mag[gx] )\n",
    "    if len(rx) > 0:\n",
    "        nelc_nde_r[c]    = len(rx)\n",
    "        nelc_tspan_r[c]  = np.max( ne_mjd[rx] ) - np.min( ne_mjd[rx] )\n",
    "        nelc_minmag_r[c] = np.min( ne_mag[rx] )\n",
    "        nelc_lcamp_r[c]  = np.max( ne_mag[rx] ) - np.min( ne_mag[rx] )\n",
    "    if len(ix) > 0:\n",
    "        nelc_nde_i[c]    = len(ix)\n",
    "        nelc_tspan_i[c]  = np.max( ne_mjd[ix] ) - np.min( ne_mjd[ix] )\n",
    "        nelc_minmag_i[c] = np.min( ne_mag[ix] )\n",
    "        nelc_lcamp_i[c]  = np.max( ne_mag[ix] ) - np.min( ne_mag[ix] )\n",
    "    del gx,rx,ix\n",
    "\n",
    "cand_field = np.asarray(tempfield, dtype='str')\n",
    "del tempfield\n",
    "\n",
    "t2 = time.time()\n",
    "print('elapsed: %5.1f' % (t2 - t1))\n",
    "del t1, t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76819fcb-7195-4fb9-924a-12102654810b",
   "metadata": {},
   "source": [
    "### 4.1. Write the lightcurve summary parameters to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f2310-abc9-4a04-ac74-bff218287209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnm = 'all_nightly_epochs_files/candidate_lightcurve_parameters.dat'\n",
    "fout = open(fnm, 'w')\n",
    "\n",
    "fout.write('# Melissa Graham, candidate_nightly_epochs.ipynb \\n')\n",
    "tnow = time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime())\n",
    "fout.write('# UTC = '+tnow+' \\n')\n",
    "del tnow\n",
    "fout.write('# \\n')\n",
    "fout.write('# Columns \\n')\n",
    "fout.write('#  0 field  \\n')\n",
    "fout.write('#  1 id -- candidate identifier \\n')\n",
    "fout.write('#  2 timespan (days between first and last detection) \\n')\n",
    "fout.write('#  3 timespan in g \\n')\n",
    "fout.write('#  4 timespan in r \\n')\n",
    "fout.write('#  5 timespan in i \\n')\n",
    "fout.write('#  6 minimum magnitude (not necessarily the peak) \\n')\n",
    "fout.write('#  7 minimum magnitude g \\n')\n",
    "fout.write('#  8 minimum magnitude r \\n')\n",
    "fout.write('#  9 minimum magnitude i \\n')\n",
    "fout.write('# 10 amplitude (magnitudes between brightest and faintest detection) \\n')\n",
    "fout.write('# 11 amplitude g \\n')\n",
    "fout.write('# 12 amplitude r \\n')\n",
    "fout.write('# 13 amplitude i \\n')\n",
    "fout.write('# 14 number of non-lonely epochs (number of unique nights detected) \\n')\n",
    "fout.write('# 15 number of non-lonely epochs in g \\n')\n",
    "fout.write('# 16 number of non-lonely epochs in r \\n')\n",
    "fout.write('# 17 number of non-lonely epochs in i \\n')\n",
    "fout.write('# \\n')\n",
    "\n",
    "for i in range(len(cand_ids)):\n",
    "    fout.write('%-8s %-14s %7.2f %7.2f %7.2f %7.2f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f '\\\n",
    "               '%6.3f %6.3f %3i %3i %3i %3i \\n' % \\\n",
    "               (cand_field[i], cand_ids[i], \\\n",
    "                nelc_tspan[i], nelc_tspan_g[i], nelc_tspan_r[i], nelc_tspan_i[i], \\\n",
    "                nelc_minmag[i], nelc_minmag_g[i], nelc_minmag_r[i], nelc_minmag_i[i], \\\n",
    "                nelc_lcamp[i], nelc_lcamp_g[i], nelc_lcamp_r[i], nelc_lcamp_i[i], \\\n",
    "                nelc_nde[i], nelc_nde_g[i], nelc_nde_r[i], nelc_nde_i[i] ) )\n",
    "\n",
    "fout.close()\n",
    "print('Wrote to: ',fnm)\n",
    "del fnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f39081-7edd-44c8-a193-6d967d1383d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
