{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c1cc48-6771-4408-ad06-a0e7d28b8fbd",
   "metadata": {},
   "source": [
    "# Create Nightly Epoch Lightcurves\n",
    "\n",
    "Author: Melissa Graham\n",
    "\n",
    "Create nightly-epoch lightcurves for \"good\" candidates, for **ALL** of the DDF not just 2021.\n",
    "\n",
    "We start by getting rid of all objects with a R/B score < 0.1, because there's definitely a locus down there \n",
    "\n",
    "\"Good\" means at least 10 objects (detections in any filter) and a mean real-bogus (mrb) score > 0.4 for all objects.\n",
    "\n",
    "We also make a \"lonely epoch\" flag for any epochs with a mrb < 0.4 **AND** for which\n",
    "there is no epoch with mrb > 0.4 within 14 days. These are more likely to be spurious\n",
    "coincidences with artifacts and we don't want to include these epochs in our\n",
    "lightcurve summary paramters like time span or amplitude.\n",
    "\n",
    "Create files that contain the lightcurves and the summary parameters.\n",
    "\n",
    "Use these files as a starting sample for transient science with the DECam deep drilling field data.\n",
    "\n",
    "Create output files in the same format as made by `candidate_nightly_epochs.ipynb`:\n",
    " * candidate_lightcurves.dat\n",
    " * candidate_lightcurve_parameters.dat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94c879-d742-4837-8d71-8d42e52ee505",
   "metadata": {},
   "source": [
    "## 0. Set up\n",
    "\n",
    "Import packages and connect to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4406d08-04a5-47d0-aefe-07b2d282fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import getpass\n",
    "import pandas\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "\n",
    "from copy import deepcopy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee172cb-f208-403e-b01d-2f788ca8ab04",
   "metadata": {},
   "source": [
    "By semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff641a-6c24-4ce5-8de3-9a3e8ee1cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "semesters = ['21A', '21B', '22A', '22B', '23A']\n",
    "sem_dates_isot = ['2021-02-01T00:00:00',\n",
    "                  '2021-08-01T00:00:00',\n",
    "                  '2022-02-01T00:00:00',\n",
    "                  '2022-08-01T00:00:00',\n",
    "                       '2023-02-01T00:00:00',\n",
    "             '2023-08-01T00:00:00']\n",
    "sem_dates = Time(sem_dates_isot, format='isot', scale='utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97836a20-bb29-4ff9-a6e5-9f976eaf001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = Time([59400,59401,59401.2,59401.3], format='mjd')\n",
    "# temp2 = temp.isot\n",
    "# temp3 = []\n",
    "# for i in temp2:\n",
    "#     temp3.append(i[0:10])\n",
    "# temp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f27ef-d5fa-4bdb-9a84-91df853207ba",
   "metadata": {},
   "source": [
    "User decat_ro, in order to access `versiontags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c7461-8a81-49f7-aab9-a92ea944e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbuser = input(\"DB User: \")\n",
    "dbpasswd = getpass.getpass(\"DB Password: \")\n",
    "db = psycopg2.connect(f\"dbname='decat' user='{dbuser}' password='{dbpasswd}' host='decatdb.lbl.gov'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720566b7-15ab-476c-a13f-834924a69300",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.autocommit = True\n",
    "cursor = db.cursor( cursor_factory = psycopg2.extras.DictCursor )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8c2f1-87c8-4d1e-80cb-faa825a525aa",
   "metadata": {},
   "source": [
    "If you want to print table schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e8a58-4585-4704-af10-9639033d203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables = ['versiontags','exposures','subtractions','images',\\\n",
    "#           'objects','objectrbs','objectdatas','objectdata_versiontag','candidates']\n",
    "# for table in tables:\n",
    "#     query = \"SELECT column_name, data_type FROM information_schema.columns WHERE table_name=%s\"\n",
    "#     cursor.execute( query, ( table, ))\n",
    "#     print( f\"\\nTABLE: {table}\\n===========================\" )\n",
    "#     for row in cursor:\n",
    "#         print( f\"{row['column_name']:24s}  :  {row['data_type']:s}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc11af-d1aa-48b3-913e-ce8ff0f8aede",
   "metadata": {},
   "source": [
    "Things in the database are tagged with versions.\n",
    "This is because we might redo something, or we might try different subtraction algorithms.\n",
    "This might change in the future, but, at the moment everything that's in the database should be tagged with the \"latest\" tag, which means it was the last thing saved to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694239b-31f3-488c-9c6f-c4a9c7bc66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"latest\"\n",
    "db.rollback()\n",
    "q = ( \"SELECT id, tag FROM versiontags WHERE tag=%(tag)s\" )\n",
    "cursor.execute( q, { \"tag\": tag } )\n",
    "row = cursor.fetchone()\n",
    "tagid = row['id']\n",
    "print(tagid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4699a12-a8d7-42a3-9c0f-8e47639e3dc5",
   "metadata": {},
   "source": [
    "## 1. Query\n",
    "\n",
    "Get all the objects in ELAIS and COSMOS fields.\n",
    "\n",
    "This takes about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58e2d9-adca-40bd-8a9b-689807d4849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "q = (\"SELECT od.ra, od.dec, od.mag, od.magerr, rbs.rb, \"\n",
    "     \"i.filter, i.meanmjd, o.candidate_id, e.proposalid \"\n",
    "     \"FROM objectdatas AS od \"\n",
    "     \"INNER JOIN objectdata_versiontag AS odvt \"\n",
    "     \"ON od.id=odvt.objectdata_id AND odvt.versiontag_id=%(tagid)s \"\n",
    "     \"INNER JOIN objects AS o ON od.object_id=o.id \"\n",
    "     \"INNER JOIN images AS i ON o.image_id=i.id \"\n",
    "     \"INNER JOIN objectrbs as rbs ON od.id=rbs.objectdata_id AND rbs.rbtype_id=2 \"\n",
    "     \"INNER JOIN exposures AS e ON i.exposure_id=e.id \"\n",
    "     \"WHERE ((od.ra > 147.0 AND od.ra < 153.0 AND od.dec > -0.25 AND od.dec < 5) \"\n",
    "     \"OR (od.ra > 5.0 AND od.ra < 12.0 AND od.dec > -46 AND od.dec < -41)) \")\n",
    "cursor.execute(q, {'tagid': tagid})\n",
    "df = pandas.DataFrame(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1169e7-a68e-412a-a061-60385ac5d63e",
   "metadata": {},
   "source": [
    "Print total number of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3ad5f-0cfb-4861-b3c0-f7cee73499ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c0283-0ba7-4d8d-8c22-257db6c720ac",
   "metadata": {},
   "source": [
    "Put the objects into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e6b80-fdc6-4fe7-9add-c92ce6bafbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_obj_ra     = np.asarray(df[0], dtype='float')\n",
    "raw_obj_dec    = np.asarray(df[1], dtype='float')\n",
    "raw_obj_mag    = np.asarray(df[2], dtype='float')\n",
    "raw_obj_mage   = np.asarray(df[3], dtype='float')\n",
    "raw_obj_rb     = np.asarray(df[4], dtype='float')\n",
    "raw_obj_filt   = np.asarray(df[5], dtype='str')\n",
    "raw_obj_mjd    = np.asarray(df[6], dtype='float')\n",
    "raw_obj_candid = np.asarray(df[7], dtype='str')\n",
    "raw_obj_propid = np.asarray(df[8], dtype='str')\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a8d45-a855-4c51-8e6c-fa346b7ee2af",
   "metadata": {},
   "source": [
    "### 1.2. Explore object properties 2021-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7611c-f984-4576-b526-1b5d85bf9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(raw_obj_mjd, bins=100)\n",
    "for x in [0, 1, 2, 3, 4, 5]:\n",
    "    plt.axvline(sem_dates[x].mjd, color='magenta')\n",
    "for x in [0, 1, 2, 3, 4]:    \n",
    "    plt.text(sem_dates[x].mjd, 270000, semesters[x])\n",
    "plt.axvline(Time.now().mjd, color='red')\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel('# Objects')\n",
    "plt.title('COSMOS & ELAIS')\n",
    "plt.savefig('all_candidate_nightly_epochs_files/cnelc_plot1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410392a-9a62-44e5-9378-b0524f0b3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 2, figsize=(10, 15), sharex=True)\n",
    "for x in [0, 1, 2, 3, 4]:\n",
    "    tx = np.where((raw_obj_mjd > sem_dates[x].mjd) & (raw_obj_mjd <= sem_dates[x+1].mjd))[0]\n",
    "    ax[x, 0].plot(raw_obj_mag[tx], raw_obj_rb[tx], 'o', ms=2, alpha=0.2, mew=0, color='grey', \n",
    "                  label=semesters[x]+' (N='+str(len(tx))+')')\n",
    "    ax[x, 0].axhline(0.1, color='black')\n",
    "    ax[x, 0].set_ylabel('rb')\n",
    "    ax[x, 0].legend(loc='upper right')\n",
    "    ax[x, 1].plot(raw_obj_mag[tx], raw_obj_mage[tx], 'o', ms=2, alpha=0.2, mew=0, color='grey')\n",
    "    ax[x, 1].set_ylim([0.0,0.5])\n",
    "    ax[x, 1].set_ylabel('mag e')\n",
    "ax[4, 0].set_xlabel('mag')\n",
    "ax[4, 1].set_xlabel('mag')\n",
    "plt.savefig('all_candidate_nightly_epochs_files/cnelc_plot2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34f752-0c7d-45b3-a473-e4aefef35bcd",
   "metadata": {},
   "source": [
    "## 2. Identify good candidates only\n",
    "\n",
    "The unique candidates for these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5487cfb-bde6-45e0-991c-818764501a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices, inverse, counts = np.unique(raw_obj_candid, return_index=True, return_inverse=True,  return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe98959-d5d2-4bbf-98c5-0e4d857c3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len(values), len(indices), len(inverse), len(counts)', len(values), len(indices), len(inverse), len(counts))\n",
    "print(' ')\n",
    "print('On average, %4.2f objects per candidate' % (len(raw_obj_candid)/len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b7477-776f-4835-9583-d79f7dce3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(np.log10(counts), bins=100, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e48c8-0546-4f12-93b2-87a06684d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f297425-6559-4d9f-8226-c9b86e8f176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.where(counts[inverse] == 1)[0]\n",
    "print(len(dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6e0bf-981b-4521-b005-3266a6a0166e",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Delete all objects with R/B < 0.1, as that is clearly a locus of \"BAD\".\n",
    "\n",
    "Delete all objects of candidates with less than 10 objects.\n",
    "\n",
    "Making the object arrays smaller speeds up the processing later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ef555-7249-4196-9f3c-0aeef573a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.where((counts[inverse] < 10) | (raw_obj_rb < 0.1))[0]\n",
    "print(len(dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ccfb8-34b0-43b5-9da4-7e6a9f429df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_ra     = np.delete(raw_obj_ra, dx)\n",
    "obj_dec    = np.delete(raw_obj_dec, dx)\n",
    "obj_mag    = np.delete(raw_obj_mag, dx)\n",
    "obj_mage   = np.delete(raw_obj_mage, dx)\n",
    "obj_rb     = np.delete(raw_obj_rb, dx)\n",
    "obj_filt   = np.delete(raw_obj_filt, dx)\n",
    "obj_mjd    = np.delete(raw_obj_mjd, dx)\n",
    "obj_candid = np.delete(raw_obj_candid, dx)\n",
    "obj_propid = np.delete(raw_obj_propid, dx)\n",
    "del dx\n",
    "del values, indices, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a3335-163f-4195-bfa8-9468e530c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices, inverse, counts = np.unique(obj_candid, return_index=True, return_inverse=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a3fbe-1dc3-4b82-88dd-b8108295e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len(values), len(indices), len(inverse), len(counts)', len(values), len(indices), len(inverse), len(counts))\n",
    "print(' ')\n",
    "print('On average, %4.2f objects per candidate' % (len(obj_candid)/len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14eded-0776-421a-8877-2a91084b774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(counts), bins=100, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a93e0-4fa9-4bf9-9719-1ba26e12e18d",
   "metadata": {},
   "source": [
    "Calculate the mean real-bogus for all remaining candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a50988-a8c4-4769-8843-e4d61fcf6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_id = values\n",
    "cand_nob = counts\n",
    "cand_mrb = np.zeros(len(cand_id), dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a3263-238b-4b2e-ad96-13b1cf80a794",
   "metadata": {},
   "source": [
    "This takes about 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaadc86-5de1-4754-affa-5ade8c27ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t0 = time.time()\n",
    "for c, cid in enumerate(cand_id):\n",
    "    if (c == 100) | (c == 1000) | (c == 10000):\n",
    "        t1 = time.time()\n",
    "        print(c, t1 - t0, 'sec')\n",
    "    cx = np.where(obj_candid == cid)[0]\n",
    "    cand_nob[c] = len(cx)\n",
    "    cand_mrb[c] = np.nanmean(obj_rb[cx])\n",
    "    del cx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b24238-31d4-47d5-8a55-88480b348dd2",
   "metadata": {},
   "source": [
    "Delete the candidates for which the mean real-bogus score is <0.4.\n",
    "\n",
    "Also delete any candidates that have < 10 objects (now that the R/B<0.1 objects are gone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbddcf-6661-4d87-a61f-7587cd2eacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.where((cand_mrb < 0.4) | (cand_nob < 10))[0]\n",
    "print(len(dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49e43d-d6a4-44a2-9849-6e56bfdf3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_ids = np.delete(cand_id, dx)\n",
    "cand_nobjs = np.delete(cand_nob, dx)\n",
    "cand_meanrb = np.delete(cand_mrb, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1898123-418d-45d7-baa6-4e791742fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cand_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f579eb7-0d83-45a5-bae4-a5319da7eedd",
   "metadata": {},
   "source": [
    "## 3. Make the lightcurve files for good objects\n",
    "\n",
    "Epochs with mean real-bogus 0.1 to 0.4 **ARE** included as points in the lightcurve file\n",
    "**AND DO** contribute to the lightcurve parameters\n",
    "**BUT NOT** if they are a lonely epoch.\n",
    "\n",
    "Lonely epoch: mean r/b <0.4 and no other r/b > 0.4 detection within 14 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45bedf-c26c-4329-96b4-97417a9b0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "temp_ne_candid = []\n",
    "temp_ne_field = []\n",
    "temp_ne_cal = []\n",
    "temp_ne_mjd = []\n",
    "temp_ne_fil = []\n",
    "temp_ne_nobj = []\n",
    "temp_ne_mag = []\n",
    "temp_ne_mage = []\n",
    "temp_ne_mrb = []\n",
    "\n",
    "for c in range(len(cand_ids)):\n",
    "    tally_ne = 0\n",
    "    \n",
    "    if (c == 10) | (c == 100) | (c == 1000):\n",
    "        t2 = time.time()\n",
    "        print(c, ((t2-t1)/float(c))*(float(len(cand_ids)-c)),' remain')\n",
    "       \n",
    "    cx = np.where(obj_candid == cand_ids[c])[0]\n",
    "    \n",
    "    if (np.mean(obj_ra[cx]) > 5.0) & (np.mean(obj_ra[cx]) < 12.0):\n",
    "        field = 'ELAIS'\n",
    "    else:\n",
    "        field = 'COSMOS'\n",
    "    \n",
    "    mjds = obj_mjd[cx]\n",
    "    temp = Time(mjds, format='mjd')\n",
    "    temp2 = temp.isot\n",
    "    temp3 = []\n",
    "    for i in temp2:\n",
    "        temp3.append(i[0:10])    \n",
    "    ucals, indices = np.unique(temp3, return_index=True)\n",
    "    umjds = mjds[indices]\n",
    "    del temp, temp2, temp3, indices\n",
    "\n",
    "    for d, mjd in enumerate(umjds):\n",
    "        \n",
    "        for f,fil in enumerate(['g','r','i']):\n",
    "            fx = np.where((np.abs(obj_mjd[cx] - mjd) < 0.4) & \n",
    "                          (obj_filt[cx] == fil) & \n",
    "                          (np.isfinite(obj_mag[cx])))[0]\n",
    "            \n",
    "            if len(fx) >= 2:\n",
    "                temp_ne_field.append(field)\n",
    "                temp_ne_candid.append(cand_ids[c])\n",
    "                temp_ne_cal.append(ucals[d])\n",
    "                temp_ne_mjd.append(np.mean(obj_mjd[cx[fx]]))\n",
    "                temp_ne_fil.append(fil)\n",
    "                temp_ne_nobj.append(len(obj_mjd[cx[fx]]))\n",
    "                temp_ne_mag.append(np.mean(obj_mag[cx[fx]]))\n",
    "                temp_ne_mage.append(np.sqrt(np.mean(obj_mage[cx[fx]])**2 + \\\n",
    "                                            np.std(obj_mag[cx[fx]])**2))\n",
    "                temp_ne_mrb.append(np.mean(obj_rb[cx[fx]]))\n",
    "                tally_ne += 1\n",
    "            \n",
    "            elif len(fx) == 1:\n",
    "                temp_ne_field.append(field)\n",
    "                temp_ne_candid.append(cand_ids[c])\n",
    "                temp_ne_cal.append(ucals[d])\n",
    "                temp_ne_mjd.append(obj_mjd[cx[fx[0]]])\n",
    "                temp_ne_fil.append(fil)\n",
    "                temp_ne_nobj.append(1)\n",
    "                temp_ne_mag.append(obj_mag[cx[fx[0]]])\n",
    "                temp_ne_mage.append(obj_mage[cx[fx[0]]])\n",
    "                temp_ne_mrb.append(obj_rb[cx[fx[0]]])\n",
    "                tally_ne += 1\n",
    "                \n",
    "            del fx\n",
    "    \n",
    "    if tally_ne == 0:\n",
    "        print('warning: ', cand_id[c], ' no nightly epochs with detections')\n",
    "    del cx\n",
    "\n",
    "ne_field  = np.asarray( temp_ne_field, dtype='str' )\n",
    "ne_candid = np.asarray( temp_ne_candid, dtype='str' )\n",
    "ne_nobj   = np.asarray( temp_ne_nobj, dtype='int' )\n",
    "ne_mjd    = np.asarray( temp_ne_mjd, dtype='float' )\n",
    "ne_cal    = np.asarray( temp_ne_cal, dtype='str' )\n",
    "ne_fil    = np.asarray( temp_ne_fil, dtype='str' )\n",
    "ne_mag    = np.asarray( temp_ne_mag, dtype='float' )\n",
    "ne_mage   = np.asarray( temp_ne_mage, dtype='float' )\n",
    "ne_mrb    = np.asarray( temp_ne_mrb, dtype='float' )\n",
    "\n",
    "del temp_ne_field,temp_ne_candid,temp_ne_nobj,temp_ne_mjd,temp_ne_cal\n",
    "del temp_ne_fil,temp_ne_mag,temp_ne_mage,temp_ne_mrb,tally_ne\n",
    "\n",
    "t2 = time.time()\n",
    "print('elapsed: ',t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0b895-e4d5-4651-8a26-407179f1409d",
   "metadata": {},
   "source": [
    "### 3.1. Create the \"lonely\" flag for low-R/B epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aab337-538d-480e-895d-28e05bac4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "ne_loneflag = np.zeros(len(ne_mrb), dtype='int')\n",
    "\n",
    "for c, cand in enumerate(cand_ids):\n",
    "    if (c == 10) | (c == 100) | (c == 1000):\n",
    "        t2 = time.time()\n",
    "        print(c, ((t2-t1)/float(c))*(float(len(cand_ids)-c)),' remain')\n",
    "    for f, filt in enumerate(['g','r','i']):\n",
    "        tx1 = np.where((ne_candid == cand) & (ne_fil == filt))[0]\n",
    "        tx2 = np.where((ne_candid == cand) & (ne_fil == filt) & (ne_mrb > 0.4))[0]\n",
    "        if len(tx1) == 1:\n",
    "            if ne_mrb[tx1[0]] < 0.4:\n",
    "                ne_loneflag[tx1[0]] = 1\n",
    "        elif (len(tx1) > 1) & (len(tx2) == 0):\n",
    "            for x1 in tx1:\n",
    "                ne_loneflag[x1] = 1            \n",
    "        elif (len(tx1) > 1) & (len(tx2) > 0):\n",
    "            for i, x1 in enumerate(tx1):\n",
    "                if ne_mrb[x1] < 0.4:\n",
    "                    nearest_good = np.min(np.abs(ne_mjd[x1] - ne_mjd[tx2]))\n",
    "                    if nearest_good > 14:\n",
    "                        ne_loneflag[x1] = 1\n",
    "                    del nearest_good\n",
    "        del tx1, tx2\n",
    "\n",
    "t2 = time.time()\n",
    "print('elapsed: ',t2-t1)\n",
    "del t1, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addbc235-0b96-4d59-bd79-8f162ca72a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.where(ne_loneflag == 1)[0]\n",
    "print('Number and fraction of lonely epochs: ', len(tx), len(tx)/len(ne_loneflag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec289d-7ea3-4184-afe9-1881b49dfb6a",
   "metadata": {},
   "source": [
    "### 3.2. Write the nightly-epoch lightcurves to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530db449-bcff-4d25-aad2-169b01767a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnm = 'all_candidate_nightly_epochs_files/candidate_lightcurves.dat'\n",
    "fout = open(fnm, 'w')\n",
    "\n",
    "fout.write('# Melissa Graham, candidate_nightly_epochs.ipynb \\n')\n",
    "tnow = time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime())\n",
    "fout.write('# UTC = '+tnow+' \\n')\n",
    "del tnow\n",
    "fout.write('# \\n')\n",
    "fout.write('# Columns \\n')\n",
    "fout.write('#  0 field  \\n')\n",
    "fout.write('#  1 id -- candidate identifier \\n')\n",
    "fout.write('#  2 calendar date \\n')\n",
    "fout.write('#  3 MJD \\n')\n",
    "fout.write('#  4 filter \\n')\n",
    "fout.write('#  5 number of objects combined \\n')\n",
    "fout.write('#  6 magnitude (mean of objects combined) \\n')\n",
    "fout.write('#  7 magnitude error \\n')\n",
    "fout.write('#  8 real/bogus (mean of objects combined) \\n')\n",
    "fout.write('#  9 lonely epoch flag \\n')\n",
    "fout.write('# \\n')\n",
    "\n",
    "for i in range(len(ne_candid)):\n",
    "    fout.write('%-9s %-14s %-8s %12.6f '\\\n",
    "               '%1s %3i %6.3f %6.3f %6.4f %1i \\n' % \\\n",
    "               (ne_field[i], ne_candid[i], ne_cal[i], ne_mjd[i], \\\n",
    "                ne_fil[i], ne_nobj[i], ne_mag[i], ne_mage[i], ne_mrb[i], ne_loneflag[i]) )\n",
    "\n",
    "fout.close()\n",
    "print('Wrote to: ',fnm)\n",
    "del fnm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c6e28-92b9-4fb0-adc3-690e10f07e9f",
   "metadata": {},
   "source": [
    "### 3.3. Calculate the lightcurve summary parameters and write to file\n",
    "\n",
    "Recall that \"lonely epochs\" are not included in the calculation of the summary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee17ed-d6c9-4c93-b249-164fd4971d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "### timespan (last date - first date of detection)\n",
    "nelc_tspan = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_tspan_g = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_tspan_r = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_tspan_i = np.zeros( len(cand_ids), dtype='float' )\n",
    "\n",
    "### minimum magnitude (brightest detection)\n",
    "nelc_minmag = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_minmag_g = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_minmag_r = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_minmag_i = np.zeros( len(cand_ids), dtype='float' )\n",
    "\n",
    "### amplitude (maximum - minimum detection)\n",
    "nelc_lcamp = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_lcamp_g = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_lcamp_r = np.zeros( len(cand_ids), dtype='float' )\n",
    "nelc_lcamp_i = np.zeros( len(cand_ids), dtype='float' )\n",
    "\n",
    "### number of epochs with detections\n",
    "nelc_nde = np.zeros( len(cand_ids), dtype='int' )\n",
    "nelc_nde_g = np.zeros( len(cand_ids), dtype='int' )\n",
    "nelc_nde_r = np.zeros( len(cand_ids), dtype='int' )\n",
    "nelc_nde_i = np.zeros( len(cand_ids), dtype='int' )\n",
    "\n",
    "tempfield = []\n",
    "\n",
    "### for every candidate\n",
    "for c, candid in enumerate(cand_ids):\n",
    "    if (c == 10) | (c == 100) | (c == 1000):\n",
    "        t2 = time.time()\n",
    "        print(c, ((t2-t1)/float(c))*(float(len(cand_ids)-c)),' remain')\n",
    "        \n",
    "    ### at first, skip the loneflag constraint to fill tempfield and check mag issues\n",
    "    cx = np.where( (ne_candid == candid) & (ne_nobj >= 1) )[0]\n",
    "    tempfield.append(ne_field[cx[0]])\n",
    "    ### where the nobj >= 1, the mag should never be nan\n",
    "    tx = np.where( np.isnan( ne_mag[cx] ) )[0]\n",
    "    if len(tx) != 0:\n",
    "        print('warning, ', candid, ' has a nobj >=1, mag=nan epoch')\n",
    "    del tx\n",
    "\n",
    "    ### but now, can apply the loneflag constraint if wanted\n",
    "    # cx = np.where( (ne_candid == candid) & (ne_nobj >= 1) )[0]\n",
    "    cx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_loneflag == 0) )[0]\n",
    "    if len(cx) > 0:\n",
    "        temp = np.unique( ne_cal[cx] )\n",
    "        nelc_nde[c] = len(temp)\n",
    "        del temp\n",
    "        nelc_tspan[c]  = np.max( ne_mjd[cx] ) - np.min( ne_mjd[cx] )\n",
    "        nelc_minmag[c] = np.min( ne_mag[cx] )\n",
    "        nelc_lcamp[c]  = np.max( ne_mag[cx] ) - np.min( ne_mag[cx] )\n",
    "    del cx\n",
    "\n",
    "    # gx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'g') )[0]\n",
    "    # rx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'r') )[0]\n",
    "    # ix = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'i') )[0]\n",
    "    gx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'g') & (ne_loneflag == 0) )[0]\n",
    "    rx = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'r') & (ne_loneflag == 0) )[0]\n",
    "    ix = np.where( (ne_candid == candid) & (ne_nobj >= 1) & (ne_fil == 'i') & (ne_loneflag == 0) )[0]\n",
    "    if len(gx) > 0:\n",
    "        nelc_nde_g[c]    = len(gx)\n",
    "        nelc_tspan_g[c]  = np.max( ne_mjd[gx] ) - np.min( ne_mjd[gx] )\n",
    "        nelc_minmag_g[c] = np.min( ne_mag[gx] )\n",
    "        nelc_lcamp_g[c]  = np.max( ne_mag[gx] ) - np.min( ne_mag[gx] )\n",
    "    if len(rx) > 0:\n",
    "        nelc_nde_r[c]    = len(rx)\n",
    "        nelc_tspan_r[c]  = np.max( ne_mjd[rx] ) - np.min( ne_mjd[rx] )\n",
    "        nelc_minmag_r[c] = np.min( ne_mag[rx] )\n",
    "        nelc_lcamp_r[c]  = np.max( ne_mag[rx] ) - np.min( ne_mag[rx] )\n",
    "    if len(ix) > 0:\n",
    "        nelc_nde_i[c]    = len(ix)\n",
    "        nelc_tspan_i[c]  = np.max( ne_mjd[ix] ) - np.min( ne_mjd[ix] )\n",
    "        nelc_minmag_i[c] = np.min( ne_mag[ix] )\n",
    "        nelc_lcamp_i[c]  = np.max( ne_mag[ix] ) - np.min( ne_mag[ix] )\n",
    "    del gx,rx,ix\n",
    "\n",
    "cand_field = np.asarray(tempfield, dtype='str')\n",
    "del tempfield\n",
    "\n",
    "t2 = time.time()\n",
    "print('elapsed: ',t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f2310-abc9-4a04-ac74-bff218287209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnm = 'all_candidate_nightly_epochs_files/candidate_lightcurve_parameters.dat'\n",
    "fout = open(fnm, 'w')\n",
    "\n",
    "fout.write('# Melissa Graham, candidate_nightly_epochs.ipynb \\n')\n",
    "tnow = time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime())\n",
    "fout.write('# UTC = '+tnow+' \\n')\n",
    "del tnow\n",
    "fout.write('# \\n')\n",
    "fout.write('# Columns \\n')\n",
    "fout.write('#  0 field  \\n')\n",
    "fout.write('#  1 id -- candidate identifier \\n')\n",
    "fout.write('#  2 timespan (days between first and last detection) \\n')\n",
    "fout.write('#  3 timespan in g \\n')\n",
    "fout.write('#  4 timespan in r \\n')\n",
    "fout.write('#  5 timespan in i \\n')\n",
    "fout.write('#  6 minimum magnitude (not necessarily the peak) \\n')\n",
    "fout.write('#  7 minimum magnitude g \\n')\n",
    "fout.write('#  8 minimum magnitude r \\n')\n",
    "fout.write('#  9 minimum magnitude i \\n')\n",
    "fout.write('# 10 amplitude (magnitudes between brightest and faintest detection) \\n')\n",
    "fout.write('# 11 amplitude g \\n')\n",
    "fout.write('# 12 amplitude r \\n')\n",
    "fout.write('# 13 amplitude i \\n')\n",
    "fout.write('# 14 number of epochs (number of unique nights detected) \\n')\n",
    "fout.write('# 15 number of epochs in g \\n')\n",
    "fout.write('# 16 number of epochs in r \\n')\n",
    "fout.write('# 17 number of epochs in i \\n')\n",
    "fout.write('# \\n')\n",
    "\n",
    "for i in range(len(cand_ids)):\n",
    "    fout.write('%-8s %-14s %7.2f %7.2f %7.2f %7.2f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f %3i %3i %3i %3i \\n' % \\\n",
    "               (cand_field[i], cand_ids[i], \\\n",
    "                nelc_tspan[i], nelc_tspan_g[i], nelc_tspan_r[i], nelc_tspan_i[i], \\\n",
    "                nelc_minmag[i], nelc_minmag_g[i], nelc_minmag_r[i], nelc_minmag_i[i], \\\n",
    "                nelc_lcamp[i], nelc_lcamp_g[i], nelc_lcamp_r[i], nelc_lcamp_i[i], \\\n",
    "                nelc_nde[i], nelc_nde_g[i], nelc_nde_r[i], nelc_nde_i[i] ) )\n",
    "\n",
    "fout.close()\n",
    "print('Wrote to: ',fnm)\n",
    "del fnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f39081-7edd-44c8-a193-6d967d1383d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
